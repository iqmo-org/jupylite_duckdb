{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrates XGBoost over Iris dataset using DuckDB and JupyterLite + Pyodide.\n",
    "\n",
    "The DuckDB usage in this example is minimal, it's just used to load the CSV, but imagine you had a more complex query & dataset.\n",
    "\n",
    "Note: In a Jupyter environment, you'd swap the jupylite_duckdb for duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas \n",
    "%pip install jupylite-duckdb\n",
    "%pip install plotly\n",
    "%pip install nbformat>=4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the only JupyterLite / Pyodide specific block.\n",
    "import jupylite_duckdb as jd\n",
    "\n",
    "# Connect (create an in-memory duckdb instance) \n",
    "conn = await jd.connect()\n",
    "\n",
    "# Get the duckdb version\n",
    "r1 = await jd.query(\"pragma version\", conn)\n",
    "display(r1)\n",
    "\n",
    "# Load the Iris dataset\n",
    "r4 = await jd.query(\"select * from read_csv_auto('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\", conn)\n",
    "display(r4.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display input data\n",
    "\n",
    "import plotly.express as px\n",
    "px.scatter(r4, x=\"sepal_length\", y=\"petal_length\", color=\"species\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import pandas as pd\n",
    "transformer = make_column_transformer(\n",
    "                # make_column_selector(dtype_exclude=numpy.number)\n",
    "                (OneHotEncoder(drop=\"first\"), [\"species\"]),\n",
    "                remainder=\"passthrough\",\n",
    "            )  # type: ignore\n",
    "\n",
    "transformed = transformer.fit_transform(r4)\n",
    "r4_encoded = pd.DataFrame(\n",
    "    transformed, columns=transformer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "r4_encoded=r4_encoded.rename(columns={col: col.replace(\"remainder__\", \"\") for col in r4_encoded if col.startswith(\"remainder__\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, _test = train_test_split(r4_encoded, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X / y\n",
    "y_col = \"sepal_length\"\n",
    "x_cols = [col for col in train if col != y_col]\n",
    "\n",
    "train_X=train[x_cols]\n",
    "train_y=train[[y_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create an XGBoost regressor\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_reg.fit(train_X, train_y)\n",
    "\n",
    "# Make predictions on the training data\n",
    "train_preds = xgb_reg.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict over Train\n",
    "train_preds = xgb_reg.predict(train_X)\n",
    "train[\"prediction\"] = train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict over Test\n",
    "test = _test\n",
    "test_X=test[x_cols]\n",
    "test_y=test[[y_col]]\n",
    "\n",
    "test_preds=xgb_reg.predict(test_X)\n",
    "test[\"prediction\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error on the training data\n",
    "mse = mean_squared_error(train_y, train_preds)\n",
    "print(\"Training MSE:\", mse)\n",
    "\n",
    "# Calculate the mean squared error on the training data\n",
    "mse = mean_squared_error(test_y, test_preds)\n",
    "print(\"Test MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Test Fit vs Training Fit\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "combined_data = pd.concat([train, test], ignore_index=True)\n",
    "combined_data[\"dataset\"] = [\"train\"] * len(train) + [\"test\"] * len(test)\n",
    "\n",
    "# Create a scatter plot of the actual and predicted values\n",
    "trace1 = go.Scatter(\n",
    "    x=train[y_col],\n",
    "    y=train[\"prediction\"],\n",
    "    mode=\"markers\",\n",
    "    name=\"Train\"\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x=test[y_col],\n",
    "    y=test[\"prediction\"],\n",
    "    mode=\"markers\",\n",
    "    name=\"Test\"\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Accuracy against Train vs Test\",\n",
    "    xaxis=dict(title=y_col),\n",
    "    yaxis=dict(title=\"Prediction\")\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iqmo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
